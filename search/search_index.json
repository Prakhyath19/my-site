{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Notes on ML, philosophy, science, books and my conjectures.</p>"},{"location":"about/","title":"About me","text":"<p>Hi I am Prakhyath.</p>"},{"location":"about/#im-at","title":"I'm at:","text":"<ul> <li>Mail: prakhyathkaryamsetty@gmail.com</li> <li>X</li> <li>Github</li> </ul>"},{"location":"mlNotes/Activation%20Functions/","title":"Activation Functions","text":"<p>11 Jul, 2024 #11.1.2</p>"},{"location":"mlNotes/Activation%20Functions/#1sigmoid","title":"1.Sigmoid","text":""},{"location":"mlNotes/Activation%20Functions/#11-function-def","title":"1.1 Function Def:","text":"<p>$$ \\sigma(z) = \\frac {1}{1 + e^{-z}} $$ </p>"},{"location":"mlNotes/Activation%20Functions/#drawbacks","title":"Drawbacks:","text":"<p>The Sigmoid Function saturates(flattens out) for large positive and large negative values. As a result, the layers don't learn anything and keeps spitting out 0s. </p> <p>They are the culprit of Vanishing/Exploding Gradients problem.</p>"},{"location":"mlNotes/Activation%20Functions/#2relu-rectified-linear-unit","title":"2.ReLU: Rectified Linear Unit","text":""},{"location":"mlNotes/Activation%20Functions/#21-function-def","title":"2.1 Function Def","text":"<p>$$ ReLU(z) = \\begin{cases} z &amp; \\text{if {z &gt; 0}} \\ 0 &amp; \\text {if {z $\\le$ 0}} \\end{cases} $$</p> <p></p> <p>Unlike the sigmoid activation function, ReLU doesn't saturate for large positive values.</p>"},{"location":"mlNotes/Activation%20Functions/#21drawbacks","title":"2.1.Drawbacks","text":""},{"location":"mlNotes/Activation%20Functions/#211-dying-relus","title":"2.1.1 Dying ReLUs","text":"<p>It outputs 0 for any value of Input is negative. During the training, some neurons die, i.e, they don't output anything than zero. This can happen due to large learning rate. For a neuron to die, it's weights must be tweaked in a way that the input of ReLU function(the weighted sum of neuron's inputs + bias term) is ==negative== for all instances in the training set.</p>"},{"location":"mlNotes/Activation%20Functions/#3leaky-relu","title":"3.Leaky ReLU","text":""},{"location":"mlNotes/Activation%20Functions/#31-function-def","title":"3.1 Function Def","text":"<p>$$LeakyReLU_{\\alpha}(z) = max(\\alpha z, z)$$</p> <p>This is a variant of ReLU. Which doesn't saturate for negative values. </p> <p>The hyperparameter $\\alpha$ determines how much the function \"leaks\": $\\alpha$ is the slope of the function for z&lt;0.</p> <p>LeakyReLU performs better than ReLU with a $\\alpha = 0.2$ </p> <p>There are other variants of ReLU such as Randomized ReLU(RReLU), Paratameterized ReLU(PReLU). ReLU and it's variants suffer from the fact that, they are not smooth functions: their derivatives abruptly change at $z = 0$. </p>"},{"location":"mlNotes/Activation%20Functions/#smooth-variants-of-relu-elu-selu","title":"Smooth Variants of ReLU: ELU, SELU","text":""},{"location":"mlNotes/Activation%20Functions/#4-elu-exponential-linear-unit","title":"4. ELU: Exponential Linear Unit","text":""},{"location":"mlNotes/Activation%20Functions/#41-function-def","title":"4.1 Function Def:","text":"<p>$$ ELU_{\\alpha}(z) =  \\begin{cases} \\alpha(exp(z) - 1) &amp; \\text{if $z$ $\\lt$ 0} \\ z &amp; \\text{if $z$ $\\ge$ 0} \\end{cases} $$</p> <p>-&gt; Outperforms all the other variants of ReLU -&gt; Training time was reduced. -&gt; The NN performed better on test set.</p>"},{"location":"mlNotes/Activation%20Functions/#42-drawbacks","title":"4.2 Drawbacks","text":"<p>-&gt; Slower to compute because of the exponential function</p>"},{"location":"mlNotes/Activation%20Functions/#5-selu-scaled-exponential-linear-unit","title":"5. SELU: Scaled Exponential Linear Unit","text":""},{"location":"mlNotes/Activation%20Functions/#51-function-def","title":"5.1 Function Def:","text":"<p>$$ SELU(z) = 1.05*ELU_{1.67}(z) $$ A scaled version of ELU (about 1.05 times ELU with $\\alpha \\approx1.67$) </p>"},{"location":"mlNotes/Activation%20Functions/#6-softmax-activation","title":"6. Softmax Activation","text":""},{"location":"mlNotes/Activation%20Functions/#61-function-def","title":"6.1 Function Def","text":"<p>$$ (\\hat{p}k) = \\sigma(\\mathbf{s(x)})_k = \\frac {exp(s_k(\\mathbf{x}))}{\\sum{j=1}^K exp(s_j (\\mathbf{x}))} \\tag{6.1}\\label{} $$</p> <p>In this equation: - $K$ is the number of classes. - Softmax score for class k</p> <p>$$ s_k(\\mathbf{x}) = (\\boldsymbol{\\theta}^k)^T \\mathbf{x} $$</p> <p>Each class has its own dedicated parameter vector $\\boldsymbol{\\theta}^k$. All these vectors are typically stores as rows in a parameter matrix $\\Uptheta$</p> <ul> <li>$\\mathbf{s(x)}$ is a vector containing the scores of each class for he instance $\\mathbf{x}$</li> <li>$\\sigma(\\mathbf{s(x)})_k$ is the estimated probability that the instance $\\mathbf{x}$ belongs to class $k$, given the scores of each class for that instance. </li> <li>$exp: e$</li> </ul> <p>$ \\eqref{6.1} \\text{ can be even written as} $</p> <p>$$</p> <p>\\sigma(\\mathbf{z})i = \\frac {e^{z_i}}{\\sum{j=1}^K e^{z_j}}</p> <p>$$ $ \\mathbf{z} = (z1,z2,...,z_K)\\in \\Bbb{R}^K $</p>"},{"location":"mlNotes/Activation%20Functions/#7-softplus","title":"7. Softplus","text":"<p>$$ Softplus(x) = \\frac {1}{\\beta} * log(1 + e^{(\\beta * x)})  $$ $$ Softplus(x) = \\frac {1}{\\beta} * log(1 + e^{(\\beta * x)}) $$</p>"},{"location":"mlNotes/Activation%20Functions/#help-when-to-use-which-activation-function","title":"Help: When to use Which Activation Function","text":"Activation Function When ReLU For all the simple tasks Swish For complex tasks Leaky ReLU Runtime Latency SELU Deep MLP"},{"location":"mlNotes/Beginners%20Introduction%20to%20Machine%20learning./","title":"Beginners Introduction to Machine learning.","text":"<p>09-05-2024 For absolute beginners</p>"},{"location":"mlNotes/Beginners%20Introduction%20to%20Machine%20learning./#1-what-is-machine-learning","title":"1 What is Machine learning","text":"<p>A program which takes some data, and predicts what happens </p>"},{"location":"mlNotes/Building%20nn%20from%20Scratch%20using%20Numpy%20and%20Pandas/","title":"Building nn from Scratch using Numpy and Pandas","text":""},{"location":"mlNotes/Glossary/","title":"Glossary","text":"<p>17 Jul, 2024</p>"},{"location":"mlNotes/Glossary/#activation-functions","title":"Activation Functions","text":""},{"location":"mlNotes/Glossary/#optimizers","title":"Optimizers","text":""},{"location":"mlNotes/Glossary/#learning-rate","title":"Learning Rate","text":""},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/","title":"Implementing Cyclic Learning Rates in Keras","text":"<p>This article assumes that the reader is familiar with the concepts of a Cyclic learnign rate and focuses on the Implementation in Keras.</p> <p>This Notebook:  [[/Notebooks]]</p> <p>For theory:</p> <ul> <li>Refer paper: Cyclical Learning Rates for Training Neural Networks by  Leslie N. Smith.</li> <li>Kudos to bckenstler's CLR repo</li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#1-little-brief-about-learning-rates-and-cyclic-learning-rates","title":"1. Little brief about Learning Rates and Cyclic Learning Rates:","text":""},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#11-what-is-learning-rate","title":"1.1 What is Learning Rate:","text":"<p>The rate at which a Neural network adapts to the new patterns in the data. Yes, we want our model to identify all the patterns in the data. So setting the learning rate to a high value seems a sensible thing to do. Nope. </p> <p>There's a trade-off:</p> <ol> <li>Setting a very high learning rate will cause the model to adapt to the new patterns fast and forgets the old patterns which it has identified before. The model will only be successful on the recent patterns but not even on the old patterns .</li> <li>Setting a low learning rate causes the model to only be effective on the patterns it has already learnt and it won't adapt to the new patterns easily.</li> </ol> <p><code>Learning rate</code> is arguably the most important hyper-parameter while training a NN. So setting the right value for the Learning rate is important.</p>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#12-leslies-hack","title":"1.2 Leslie's Hack","text":"<p>If the maximum value is too rapidly adapting and the minimum value is too slowly adapting, then why not use a learning rate that cycles between the min value and the max value. In this way, the NN can adapt the new patterns and keep track of the old patterns.</p>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#2-implementing-cylic-learning-rate-in-keras-on-mnist-dataset","title":"2. Implementing Cylic learning Rate in Keras on MNIST dataset","text":"<p>Leslie putforths in his paper that using cyclic lerning rates and a big batch size will help the model converge faster and yield better results.</p> <p>So, these are the two metrics we are watching for: Speed and Accuracy.</p>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#21-with-a-constant-learning-rate","title":"2.1. With a Constant Learning Rate","text":"<ul> <li>We've build a Neural Network with 3 dense layers, with each layer with neurons 100, 50, 10 respectively. </li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#211-compiling-the-model","title":"2.1.1 Compiling the Model:","text":"<ul> <li>Activation Function: We use <code>softmax</code> as the activation function for each layer in the network</li> <li>Loss: <code>categorical_crossentropy</code></li> <li>Optimizers: <code>Adam</code> with <code>learning_rate = 0.1</code></li> <li>metrics: <code>categorical_crossentropy_accuracy</code></li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#212-fitting-the-model","title":"2.1.2 Fitting the model:","text":"<ul> <li>Epochs = 15</li> <li>batch_size = 100</li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#213-results","title":"2.1.3 Results","text":"<ul> <li>Time taken for training the Network:  30.209205443000428s</li> <li>Validation Accuracy:0.7598</li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#22-with-cyclic-learning-rate","title":"2.2 With Cyclic Learning Rate","text":"<ul> <li>We use the same architecture as before with three layers of neuros 100,50,10 respectively.</li> <li>We implement the Cyclic learning rate as a callback.</li> <li>clone the repo CLRrepo in your current working directory where your notebook resides.</li> <li>Import callbacks abd clr_callback<ul> <li>from keras.callbacks import *</li> <li>from clr_callback import *</li> </ul> </li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#221-compling-the-cyclic-model","title":"2.2.1 Compling the Cyclic Model.","text":"<p>Same as in Compiling the model</p>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#222-fitting-the-model","title":"2.2.2 Fitting the model:","text":"<ul> <li>We initialize the CylcicLR instance with the <code>triangular</code> policy and set it to <code>clr_traingular</code> variable.</li> <li>We'll set this <code>clr_traingular</code> variable to callbacks as a list.</li> <li>Epochs = 15</li> <li>batch_size = 2000</li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#223-results","title":"2.2.3 Results","text":"<ul> <li>Time taken for training the neural net:  5.474767358999998 s</li> <li>Validation Accuracy: 0.8352</li> </ul>"},{"location":"mlNotes/Implementing%20Cyclic%20Learning%20rates%20in%20Kears/#3-conclusion","title":"3. Conclusion:","text":"<p>The results are self-explanatory that the model performed faster and better with Cyclic Learning rate with a bigger batch_size than with a Constant Learning Rate with a small batch_size.</p>"},{"location":"mlNotes/Regularization/","title":"Regularization","text":"<p>18 Jul, 2024</p>"},{"location":"mlNotes/Regularization/#1-early-stopping","title":"1. Early Stopping","text":""},{"location":"mlNotes/Regularization/#2-ell-1-and-ell-2-regularization","title":"2. $\\ell 1$ and $\\ell 2$ Regularization","text":"<p>For simple linear models, $\\ell 2$ regularization to constrain a neural network's connection weights </p>"},{"location":"mlNotes/Regularization/#3-dropout","title":"3. Dropout","text":""},{"location":"mlNotes/Regularization/#4-max-norm-regularization","title":"4. Max-norm regularization","text":""},{"location":"mlNotes/Training%20Deep%20NN/","title":"Training Deep NN","text":"<ol> <li>[[Understanding Vanishing and Gradients Problem]]</li> <li>[[Reusing Pretrained Layers]]</li> <li></li> </ol>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/","title":"Understanding Vanishing and Gradients Problem","text":"<p>11 Jul, 2024 #11.1.1</p>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#1defining-the-problem","title":"1.Defining the Problem:","text":"<p>During the Training of the NN, the NN computes the values of each parameter in the network in the  Forward Pass. Now, during the Backward Pass it computes the gradient of the cost function with regard to each parameter in the network. The NN uses these gradients to update each parameter with a gradient descent step.</p> <p>With Deep NN, the gradients-while going from outer layer to inner layers-become smaller and smaller and make virtually no difference on the inner layers. i.e, the gradients become so small that the inner layers remain unchanged, and learning would be ceased. This is called Vanishing Gradients Problem.</p> <p>The opposite case also exists. The Gradients keeps growing and growing as they propagate backward and they make inner layers update by huge margins that the model diverges. This is called Exploding Gradients Problem. This is often seen in RNNs.</p>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#2-whats-causing-this-problem","title":"2. What's causing this Problem?","text":"<p>In their paper by Xavier Glorot and Yoshua Bengio: Understanding the Difficulty of Training Deep Feedforward Neural Networks found that there are two main culprits that are causing this problem. 1. The Sigmoid Activation Function 2. The weight initialization Technique</p> <p>The combination of this Activation function and Weight Initialization scheme, the variance of the outputs of each layer is much greater than the variance of it's inputs. During the Forward pass, the variance of each layer keeps increasing until the activation function saturates at the top layers. </p>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#21-culprit-a-peek-into-sigmoid-activation-function","title":"2.1 Culprit: A Peek into Sigmoid Activation Function","text":"<p>![[Sigmoid Activation Function.png]] When the inputs become larger, the function saturates at 1; conversely, when the inputs become largely negative, the function saturated at 0. In both the cases, they flatten out. So, during the backward pass, there is little to no gradient that exists that can propagate to the inner layers. And no learning would eventually take place.</p>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#3-solutions","title":"3. Solutions","text":""},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#31-glorot-and-he-initialization","title":"3.1 Glorot and He initialization","text":"<p>Dubbed: Don't let the signal die method. The signal should flow properly in the forward pass-making predictions, and during the backward pass-propagating gradients. The signal shouldn't die out nor explode.</p> <p>To keep the signal alive, authors propose 1) the variance of the outputs should be equal to the variance of inputs in the forward pass. 2) The gradients should have equal variance before and after flowing through a layer in the backward pass.</p> <p>Note: Unless we have equal no.of inputs and outputs in each layer, these two conditions would not meet. Theses numbers are fan<sub>in</sub> , fan<sub>out</sub> , of the layer.</p> <p>Glorot and Bengio's proposal: The Connection weights of each layer must be initialized randomly, where, $$fan_{avg} = \\frac {fan_{in} + fan_{out}}{2}$$</p> <p>Other Initializations:  Lecun Initialization, He initialization.</p>"},{"location":"mlNotes/Understanding%20Vanishing%20and%20Gradients%20Problem/#311-initializations-and-their-activations","title":"3.1.1 Initializations and their Activations","text":"Initialization Activation Functions $\\sigma^2$ (Normal) Glorot None, tanh, sigmoid, softmax 1/$fan_{avg}$ He ReLU, Leaky ReLU, ELU, GELU, Swish, Mish 2/$fan_{in}$ LeCun SELU 1/$fan_{in}$ More on [[Activation Functions]] ### 3.2 Batch Normalization Math heavy content: #readlater ### 3.3 Gradient Clipping During the Backpropagation, the gradients are clipped, so  that, they don't exceed the set threshold. -&gt; Used in RNNs, where batchNorm is usually tricky to implement."},{"location":"mlNotes/mlNotes_index/","title":"ML Notes","text":""},{"location":"mlNotes/mlNotes_index/#repos-and-notes","title":"Repos and Notes","text":""},{"location":"mlNotes/mlNotes_index/#1-implenting-cylclic-learning-rates-in-keras","title":"1. Implenting Cylclic Learning Rates in keras","text":""},{"location":"mlNotes/mlNotes_index/#2-activation-functions","title":"2. Activation Functions","text":""},{"location":"mlNotes/mlNotes_index/#3-understanding-vanishing-and-gradients-problem","title":"3. Understanding Vanishing and Gradients Problem","text":""},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/","title":"Implementing Cyclic Learning Rates in Keras","text":"<p>This article assumes that the reader is familiar with the concepts of a Cyclic learnign rate and focuses on the Implementation in Keras.</p> <p>For theory: - Refer paper: Cyclical Learning Rates for Training Neural Networks by  Leslie N. Smith. - Kudos to bckenstler's CLR repo</p>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#1-little-brief-about-learning-rates-and-cyclic-learning-rates","title":"1. Little brief about Learning Rates and Cyclic Learning Rates:","text":""},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#11-what-is-learning-rate","title":"1.1 What is Learning Rate:","text":"<p>The rate at which a Neural network adapts to the new patterns in the data. Yes, we want our model to identify all the patterns in the data. So setting the learning rate to a high value seems a sensible thing to do. Nope. </p> <p>There's a trade-off: 1. Setting a very high learning rate will cause the model to adapt to the new patterns fast and forgets the old patterns which it has identified before. The model will only be successful on the recent patterns but not even on the old patterns . 2. Setting a low learning rate causes the model to only be effective on the patterns it has already learnt and it won't adapt to the new patterns easily.</p> <p><code>Learning rate</code> is arguably the most important hyper-parameter while training a NN. So setting the right value for the Learning rate is important.</p>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#12-leslies-hack","title":"1.2 Leslie's Hack","text":"<p>If the maximum value is too rapidly adapting and the minimum value is too slowly adapting, then why not use a learning rate that cycles between the min value and the max value. In this way, the NN can adapt the new patterns and keep track of the old patterns.</p>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#2-implementing-cylic-learning-rate-in-keras-on-mnist-dataset","title":"2. Implementing Cylic learning Rate in Keras on MNIST dataset","text":"<p>Leslie putforths in his paper that using cyclic lerning rates and a big batch size will help the model converge faster and yield better results.</p> <p>So, these are the two metrics we are watching for: Speed and Accuracy.</p>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#21-with-a-constant-learning-rate","title":"2.1. With a Constant Learning Rate","text":"<ul> <li>We've build a Neural Network with 3 dense layers, with each layer with neurons 100, 50, 10 respectively.   #### 2.1.1 Compiling the Model:</li> <li>Activation Function: We use <code>softmax</code> as the activation function for each layer in the network</li> <li>Loss: <code>categorical_crossentropy</code></li> <li>Optimizers: <code>Adam</code> with <code>learning_rate = 0.1</code></li> <li>metrics: <code>categorical_crossentropy_accuracy</code>  #### 2.1.2 Fitting the model:</li> <li>Epochs = 15</li> <li>batch_size = 100  #### 2.1.3 Results</li> <li>Time taken for training the Network:  30.209205443000428s</li> <li>Validation Accuracy:0.7598</li> </ul>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#22-with-cyclic-learning-rate","title":"2.2 With Cyclic Learning Rate","text":"<ul> <li>We use the same architecture as before with three layers of neuros 100,50,10 respectively.</li> <li>We implement the Cyclic learning rate as a callback.</li> <li>clone the repo CLRrepo in your current working directory where your notebook resides.</li> <li>Import callbacks abd clr_callback<ul> <li>from keras.callbacks import *</li> <li>from clr_callback import *</li> </ul> </li> </ul>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#221-compling-the-cyclic-model","title":"2.2.1 Compling the Cyclic Model.","text":"<p>Same as in Compiling the model</p>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#222-fitting-the-model","title":"2.2.2 Fitting the model:","text":"<ul> <li>We initialize the CylcicLR instance with the <code>triangular</code> policy and set it to <code>clr_traingular</code> variable.</li> <li>We'll set this <code>clr_traingular</code> variable to callbacks as a list.</li> <li>Epochs = 15</li> <li>batch_size = 2000</li> </ul>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#223-results","title":"2.2.3 Results","text":"<ul> <li>Time taken for training the neural net:  5.474767358999998 s</li> <li>Validation Accuracy: 0.8352</li> </ul>"},{"location":"mlNotes/Notebooks/Cyclic-learning-rates/CLR/#3-conclusion","title":"3. Conclusion:","text":"<p>The results are self-explanatory that the model performed faster and better with Cyclic Learning rate with a bigger batch_size than with a Constant Learning Rate with a small batch_size.</p>"},{"location":"notes/Atomic%20Habits/","title":"Atomic Habits","text":"<p>Date: 2023-09-29</p>"},{"location":"notes/Atomic%20Habits/#structural-notes","title":"Structural Notes:","text":"<ol> <li>What kind of book is this?</li> <li>What is it about as a whole? Key themes of the book:</li> <li>One of the core themes of this book is to focus on systems instead of goals for progress and changing the habits.</li> <li>The goal is using habits as a means to change our Identity not to reach an outcome.</li> <li>Feedback loops.</li> <li>Structure:</li> <li>The book is divided in to 6 chapters. </li> <li>The first chapter The Fundamentals talks about why and how atomic habits are powerful.</li> <li>The next 4 Chapters deal with the Four Laws of behaviour change.<ol> <li>Make it Obvious</li> <li>Make it Attractive</li> <li>Make it Easy</li> <li>Make it Satisfying</li> </ol> </li> <li>The final chapter deals with fine-tuning of the habits and system that's been set.</li> </ol>"},{"location":"notes/Atomic%20Habits/#part-1-the-fundamentalswhy-tiny-changes-make-a-big-difference","title":"Part-1: The Fundamentals(why Tiny changes make a big difference)","text":""},{"location":"notes/Atomic%20Habits/#chapter-1-the-surprising-power-of-atomic-habits","title":"Chapter-1: The Surprising Power of Atomic Habits.","text":"<p>Aggregation of marginal gains:  The philosophy of searching for a tiny margin of improvement in everything we do.</p> <p>-&gt; Take everything about the thing that goes into doing the task or routine that you want to do and improve them by 1%.- TODO</p> <p>If we get better everyday by 1% for one year, you'll end up 37% times better by the time you're done. Conversely, if we get worse each day by 1% for 1 year, we'll decline nearly down to zero.</p> <p>-&gt; Try with math - addition, subtraction and stuff. Measure if the performance is improved by 37%. We can measure it with respect to time and accuracy. TODO</p> <p>The problem is small changes don't reap immediate results. The changes only become noticeable by months, a year, 2 years, 10 years. Only for a time frame like this the value of good habits and the cost of bad habits become strikingly apparent. </p> <p>A single decision is easy to dismiss, It doesn't have any immediate fatal consequences. So, we do it. And we do it again and again. As we are inherently not wired to understand the exponential function(which includes the compound interest function), we do it. And the consequences come into the picture all at once. But when we repeat these 1% errors day after day after everyday, by replicating poor decisions, duplicating tiny mistakes( [[The art of thinking clearly]] ), rationalising little excuses, our small choices compound into toxic results.</p> <p>-&gt; List down what you know that you are doing wrong, and are still doing as it doesn't have any significant effect on the immediate future or the present. And stop doing them. -TODO 1. Gym 2. Walking 3. Eating in moderation 4. Reading everyday and asking the 4 question from htrab. 5. Bathing in the morning 6. Applying oil regularly 7. </p>"},{"location":"notes/Atomic%20Habits/#trajectory-is-more-important-than-results","title":"Trajectory is more important than results:","text":"<p>If you want to predict where you'll end up in life, all you have to do is follow the curve of tiny gains or tiny losses. And see how your daily choices will compound ten or twenty years down the line.  ![[Pasted image 20230929181351.jpg]]</p>"},{"location":"notes/Atomic%20Habits/#what-progress-looks-like","title":"What progress looks like?","text":"<p>Breakthrough moments are often the result of many previous accumulations, which build up the potential required to unleash a major change. Cancer spends 80% of it's life undetectable, then takes over the body in months(bad habits). Bamboo spends the first 5 years and builds it's extensive root system under the soil and shoots up to 90 feet into the air in the next 6 weeks.(Good habits)</p> <p>Habits are the same. They seem to make no difference until we cross a critical threshold and unlock a new level of performance. In the early and middle stages of any quest, there's a valley of disappointment. ![[Pasted image 20230929182842.jpg]] The people who cross the valley of disappointment, unlock the real benefits of their atomic habits.</p> <p>Question: What determines whether we stick with a habit long enough to survive the Plateau of latent Potential and break through to the other side? What is the that causes some people to slide into unwanted habits and enables others to enjoy the compounding effects of the good ones? Answer: Focus on Systems instead of Goals</p>"},{"location":"notes/Atomic%20Habits/#focus-on-systems-instead-of-goals","title":"Focus on Systems instead of Goals","text":"<p>We think that we need goals to achieve success in what we do. This is false in part. The case will be made below shortly. 1. Winners and losers have the same goals:     Every team that participate in a tournament have the same goal to win the world cup. But only one team does that. The winners and losers had the same goals, but only one succeeded. As they implemented a system of small improvements.    Goal setting suffers from a serious case of survivorship bias. We concentrate on the people who end up winning - the survivors- and mistakenly assume that ambitious goals led to their success while overlooking all of the  people who had the same objective but didn't succeed. 2. Achieving a goal is only a momentary change(IMPORTANT):     Imagine we have a messy room and we set our goal to clean it. We summon the energy to finally to do clean it, and we clean it(after many rounds of procrastination). We've cleaned the room - for now. If we maintain the same sloppy, pack-rat habits that led to a messy room in the first place, we'll soon end up with a new set of mess. And we'll be looking for another round of incredible energy to clean the room. We're chasing the same outcome. Despite achieving the goal, we're again and again chasing the same goal. This is recurrent because we've never changed the system.     We've treated a symptom without addressing the cause.    We need to solve the problems at systems level-fix the inputs and the outputs will fix themselves. 3. Goals restrict our idea of happiness:    Goals create an \"either or\" conflict: If we achieve our goal we tell ourselves that we are successful, if we don't we treat ourselves as an utter disappointment.     When we adopt the system-first mentality we fall in love with the process rather than the outcome. We don't have to wait till the outcome is achieved to be happy. We can indeed be at peace while performing the task at hand.</p> <p>A final note on systems and goals</p> <p>Goals set the direction, Systems enable the motion in that direction.</p>"},{"location":"notes/Atomic%20Habits/#a-system-of-atomic-habits","title":"A System of Atomic Habits","text":"<p>You do not rise to the level of your goals, you fall to the level of your systems.</p> <p>Focusing on the overall system, rather than a single goals is one of the core themes of this book. </p> <p>Atomic Habits-small and mighty-regular practice or routine that is not only small and easy to do, but also the source of incredible power. </p> <p>They are small and when piled up on one another they come to fruition.</p> <p>2023-10-06 | 01:05 Didn't read the book since 4 days. And I'm here making notes.</p>"},{"location":"notes/Atomic%20Habits/#chapter-2-identity-based-habits","title":"Chapter-2: Identity Based Habits","text":"<p>Why is it easy to repeat bad habits and so hard to form the good ones? Changing habits can be challenging for two reasons: 1. We try to change the wrong thing 2. We try to change our habits in the wrong way. Three Layers of Behaviour Change: (Not to be confused with Four laws of behaviour change made by James in the conclusion of the book) ![[Pasted image 20231006012541.png]] 1. Outcome based: Concerned with changing the results     Losing weight, Publishing a book, etc.. 1. Process based: Concerned with changing the habits and the systems     Developing a new routine at the gym, decluttering my desk before I start to work. 3. Identity based: Concerned with changing you beliefs     Your self-image, your judgments about yourself and others.</p> <p>Outcomes are about what you get, Processes are about what you do, identity is about what you believe.</p> <p>The problem is not that one level is better or worse than the another, all levels of change are useful in their own way. The problem is in the direction of change.</p> <p>Most people don't even consider identity change when they set out to improve. This is the typical approach people have: GOAL(losing weight) -&gt; PROCESS(sticking to a diet) -&gt; OUTCOME(lean body).  If I do this process then I'll lose weight. They have their goals in place and their plans to act to progress in that direction. But, but they never really don't change their beliefs that drive those actions-they don't change the way they look at themselves.  They don't realise that their old identity can sabotage their new plans for change.</p> <p>Identity change is not a joke. This really is powerful. Believe what kind of a person you are. You'll naturally progress towards your goals. Once you start taking pride in who you are, you'll fight tooth and nail to maintain your habits. </p> <p>Unity of the chapter: True behaviour change is identity change. You might start a habit because of motivation, but the only reason we'll stuck with one is that it becomes part if our identity. Anyone can convince themselves to go the gym once or twice, but if we don't shift the belief behind the behaviour, then it is hard to stick with the long-term changes. Improvements are only temporary until they become part of who we are.</p> <p>The goal is not to read a book, the goal is to become a reader. The goal is not to program everyday, the goal is to be an expert in ml Thee goal is not to go to gym everyday, the goal is to become a GYMRAT</p> <p>Doing the right thing is easy, despite the difficulties because our identity and behaviour are aligned.</p>"},{"location":"notes/Atomic%20Habits/#the-other-edge-of-identity-change","title":"The Other edge of Identity Change","text":"<p>What we believe is who we are, consciously or non-consciously. As with the benefits, identity change can be the primary cause that impedes our growth.  1. I'm horrible at math 2. I can't stay awake after lunch 3. My hair doesn't look good. 4. I'll go later to go the gym today. Many other variations like these...</p> <p>The more deeply a thought or action is tied to your identity, the more difficult it is to change it. It can feel comfortable to believe what your culture believes(group identity), or to do what upholds your self-image.(personal identity). </p> <p>The biggest barrier to positive change at any level-individual,team,society-is identity conflict.</p> <p>On any given day, you may struggle with your habits because you're too busy or too tired or too overwhelmed or hundreds of other bull shit reasons. Over the long run, however the real reason is that our self-image gets in the way.</p> <p>Q. Beliefs, beliefs, beliefs. They are the core of identity formation. Behaviour change. If they are so crucial, where do we actually adapt these beliefs from?</p>"},{"location":"notes/Atomic%20Habits/#two-step-process-to-changing-your-identity","title":"Two-step process to changing your identity.","text":"<p>There exists no belief that exists without origin,  beliefs are basically our built-up experiences. We form a belief based on evidence we have for that certain thing.</p> <ol> <li>Build evidence to show yourself what kind of a person you are. This creates strong beliefs. </li> <li>The frequency of which a certain habit is performed will influence our identity.</li> </ol> <p>BUILD evidence, do it FREQUENTLY; identity : repeated beingness(essentitas-being, identidem-repeatedly)</p> <p>New identities require new evidence. If we keep casting the same vote we've always cast, we're going to get the same results we've always got. If nothing changes, nothing will change. The two-step process to change identity: 1. Decide the type of person you want to be.     First decide who you want to be. This holds at any level- as individual,team,society, nation. What do you stand for? What are your principals and values? Who do you wish to become?     Answering these from bottom-up is hard. It's easier to work top-bottom. Start with the type of results you want to achieve.And then work backwards.     Ex:     1. Who is the type of person that can get SIX-pack: The one who eats proper food and maintains calorie deficit.     2. Who is the type of person that is well-versed with DATA SCIENCE: The one who daily invests decent hours of his life to learning things in DS and writes code.     Constantly keep asking yourself, do the people whom you aspire to become would perform this task in this way. 2. Prove it to yourself with small wins     Win at performing the habit. Everyday. </p> <p>Identity-based habits are the introduction to feedback loops. Your habits shape your identity, your identity shape your habits. Let your values, principles and identity drive the loop rather than your results. The focus should always be on becoming the type of person, not getting a particular goal or outcome. </p>"},{"location":"notes/Atomic%20Habits/#chapter-epilogue","title":"Chapter Epilogue","text":"<p>The true question is: Are you becoming the type of person you want to become? The first step is not how or what, but who. Habits can bring everything you want in life(fit body, career success). But, habits are not about having something. They are about becoming someone.</p> <p>2023-10-30</p>"},{"location":"notes/Atomic%20Habits/#chapter-3-how-to-build-better-habits-in-4-simple-steps","title":"Chapter-3: How to build Better Habits in 4 simple steps","text":"<p>In 1898, a psychologist named Edward Thorndike conducted an experiment on cats. Put them in a box-kept a lever at the end-when  the lever was pressed-at the opening there was food. </p> <p>Behaviours followed by satisfying consequences tend to be repeated and those that produce unpleasant consequences are less likely repeated.</p> <p>A habit is a behaviour that has been repeated enough times to become automatic</p>"},{"location":"notes/Crippled%20Articulation./","title":"Crippled Articulation.","text":"<p>Useful Links: wikidiff</p> <p>Lot many words, a lot of non-intelligible words, a few familiar words, and very few words we actually understand and use.\u00a0</p> <p>Communication is central to intelligence. Communicating is the display of intelligence. Communication boils down to words. Alphabets don\u2019t make much sense when used alone.\u00a0</p> <p>We suck at using words. Most of our vocabulary is similar to that of a 10th grader. After some time we hit a stagnation to learn words as we stand in the way of learning one when we see one.</p> <p>My conjecture is that we try to understand the word by looking up for a familiar synonym instead of understanding the nuance.</p> <p>Doing this gives us power\u2014the power of articulating feelings and thoughts with great conviction. Our message will penetrate the depths of our psyche and the others who read it. Who actually read it.</p>"},{"location":"notes/notes_index/","title":"Notes","text":"<p>The notes include from books, personal thoughts, philosophy and science.</p>"},{"location":"notes/notes_index/#1-crippled-articulation","title":"1. Crippled Articulation","text":""},{"location":"notes/notes_index/#2-atomic-habits-notes","title":"2. Atomic Habits Notes","text":""}]}